# ğŸš• NYC Taxi Fare Predictor

A beautiful, modern web application for predicting New York City taxi fares using machine learning.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-ML-green.svg)

## âœ¨ Features

- ğŸ¯ **AI-Powered Predictions** - 86.23% accuracy using XGBoost
- ğŸ—ºï¸ **Interactive Maps** - Visual route display with Folium
- ğŸ“ **NYC Landmarks** - Quick selection of popular locations
- ğŸ’° **Detailed Breakdown** - See fare components and estimates
- ğŸ¨ **Modern UI** - Beautiful gradient design with smooth animations
- ğŸ“± **Responsive** - Works on desktop and mobile

## ğŸš€ Quick Start

### Prerequisites

1. **Download Dataset** from Kaggle:
   - Visit: https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data
   - Download `train.csv` and `test.csv`
   - Place them in `data/raw/` directory

### Setup Instructions

#### 1. Clone Repository

```bash
git clone https://github.com/Rayudualapati-25/python-project.git
cd python-project
```

#### 2. Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # On macOS/Linux
# OR
.venv\Scripts\activate  # On Windows
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Place Dataset Files

```bash
# Create data directory if it doesn't exist
mkdir -p data/raw

# Move your downloaded CSV files
mv ~/Downloads/train.csv data/raw/
mv ~/Downloads/test.csv data/raw/
```

#### 5. Train the Model

```bash
python train.py
```

This will:
- Load and process `data/raw/train.csv`
- Train XGBoost model with feature engineering
- Save trained pipeline to `taxi_fare_pipeline.pkl`
- Display training metrics and validation results

Training typically takes 5-15 minutes depending on your hardware.

#### 6. Generate Predictions (Optional)

```bash
python predict.py
```

This will:
- Load the trained model
- Process `data/raw/test.csv`
- Generate predictions in `data/processed/predictions.csv`

#### 7. Run the Web App

```bash
streamlit run app.py
```

The app will automatically open at `http://localhost:8501`

## ğŸ“‹ Requirements

- Python 3.8+
- streamlit
- pandas
- numpy
- scikit-learn
- xgboost
- folium
- streamlit-folium

## ğŸ® How to Use

1. **Select Pickup Location** - Choose from NYC landmarks or enter custom coordinates
2. **Select Dropoff Location** - Choose your destination
3. **Set Date & Time** - Pick your desired pickup time
4. **Choose Passengers** - Select number of passengers (1-6)
5. **Click Predict** - Get your estimated fare!

## ğŸ† Model Performance

Expected performance after training on the full dataset:

- **RÂ² Score:** ~86-88%
- **RMSE:** $3-4
- **Training Time:** 5-15 minutes (depends on hardware and sample size)

Performance metrics will be displayed after running `train.py`.

### Sample Output
```
MODEL EVALUATION
==================================================
Training RÂ² Score: 0.8756
Validation RÂ² Score: 0.8623
Training RMSE: $3.12
Validation RMSE: $3.59
```

## ğŸ¨ Features Showcase

### ğŸŒˆ Modern UI Design
- Gradient backgrounds (Purple to Blue theme)
- Glassmorphism cards
- Smooth animations and transitions
- Responsive layout

### ğŸ“Š Interactive Visualizations
- Real-time route mapping
- Distance calculations (km and miles)
- Fare breakdown charts
- Estimated trip duration

### ğŸ™ï¸ NYC Landmarks Included
- Times Square
- Statue of Liberty
- Central Park
- JFK Airport
- LaGuardia Airport
- Newark Airport
- Metropolitan Museum
- World Trade Center
- Brooklyn Bridge
- Empire State Building

## ğŸ“ Project Structure

```
python-project/
â”œâ”€â”€ app.py                          # Streamlit web application
â”œâ”€â”€ train.py                        # Model training script
â”œâ”€â”€ predict.py                      # Batch prediction script
â”œâ”€â”€ taxi_fare_pipeline.pkl          # Trained ML model (generated)
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ .gitignore                      # Git ignore rules
â””â”€â”€ data/
    â”œâ”€â”€ raw/                        # Place train.csv and test.csv here
    â”‚   â”œâ”€â”€ train.csv              # Training dataset (download from Kaggle)
    â”‚   â””â”€â”€ test.csv               # Test dataset (download from Kaggle)
    â””â”€â”€ processed/                  # Generated predictions
        â””â”€â”€ predictions.csv        # Model predictions (generated)
```

## ğŸ”§ Technical Details

### Model Architecture
- **Algorithm:** XGBoost Regressor
- **Features:** 20 engineered features
- **Hyperparameters:**
  - n_estimators: 300
  - max_depth: 7
  - learning_rate: 0.1
  - subsample: 0.8
  - colsample_bytree: 0.8

### Feature Engineering Pipeline
1. **DateTime Features** - Extract year, month, day, weekday, hour from pickup_datetime
2. **Trip Distance** - Calculate haversine distance between pickup and dropoff
3. **Landmark Distances** - Distance to JFK, LGA, EWR, Met Museum, WTC (10 features)
4. **Outlier Removal** - Filter invalid coordinates, unreasonable fares
5. **Feature Selection** - Select 20 most relevant features

### Training Pipeline (`train.py`)
```python
# Load data with optional sampling
df = pd.read_csv('data/raw/train.csv')

# Feature engineering pipeline
Pipeline([
    ('datetime_features', DatetimeFeatureExtractor()),
    ('distance', DistanceCalculator()),
    ('landmarks', LandmarkDistanceCalculator()),
    ('outlier_removal', OutlierRemover()),
    ('feature_selection', FeatureSelector())
])

# Train XGBoost
model = XGBRegressor(n_estimators=300, max_depth=7, ...)
model.fit(X_train, y_train)
```

### Prediction Pipeline (`predict.py`)
```python
# Load trained model
pipeline_data = pickle.load('taxi_fare_pipeline.pkl')

# Transform test data
X_test = pipeline_data['feature_pipeline'].transform(test_df)

# Generate predictions
predictions = pipeline_data['model'].predict(X_test)
```

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ‘¨â€ğŸ’» Author

Built with â¤ï¸ using Streamlit and XGBoost

## ğŸ™ Acknowledgments

- Dataset: NYC Taxi & Limousine Commission
- Framework: Streamlit
- ML Library: XGBoost
- Mapping: Folium

---

**Made with ğŸš• in NYC**
